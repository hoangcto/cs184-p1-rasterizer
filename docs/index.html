<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
    <style>
        body {
            padding: 100px;
            width: 1000px;
            margin: auto;
            text-align: left;
            font-weight: 300;
            font-family: 'Open Sans', sans-serif;
            color: #121212;
        }

        h1, h2, h2, h4 {
            font-family: 'Source Sans Pro', sans-serif;
        }
    </style>
    <title>CS 184 Rasterizer</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet" />
</head>


<body>

    <h1 align="center">CS 184/284a: Computer Graphics and Imaging, Spring 2023</h1>
    <h1 align="center">Project 1: Rasterizer</h1>
    <h2 align="center"> Hoang To and David Tai </h2>

    <br />

    <div>

        <h2 align="center">Overview</h2>
        <p>
            Our project involved implementing a rasterizer, a program that generates images from svg files using triangles as the underlying building block. 
            The rasterizer's main functionalities were supersampling, barycentric coordinate interpolation, and texture mapping. In this write-up, we demonstrate the implementation of these three features and provide results that showcase their ability to enhance the quality of renderings. 
            Supersampling is used to conduct anti-aliasing, which eliminates jagged edges in images. Barycentric coordinates allow for gradient coloring, while texture mapping makes use of Mipmaps and bilinear interpolation to efficiently apply an anti-aliased texture to a scene. 
            Despite facing significant debugging challenges, we found the project to be highly fulfilling. The qualitative results presented here serve as evidence of this.
        </p>

        <h2 align="center">Task 1: Drawing Single-Color Triangles</h2>
        <p>
            To rasterize a triangle from three screenspace coordinates and an RGB color vector, we first define a bounding box around the coordinates and determine which pixels lie within the triangle. 
            For each (x,y) sample, we used the line test on each edge of the triangle to determine whether a screenspace point in the search box lies within the triangle. We ran into issues in which direction/plane the line test supposed to go and came up with an algorithm that checked if a screen point is on the same half-plane with the third vertice.
            The resulting pixels are colored with the input color. Figure 1 shows an example of triangle rasterization for a sparse collection of triangles.
        </p>
        <div align="center">
            <img src="images/Task1.png" align="middle" width="400px" />
            <figcaption align="center"> <b>Figure 1:</b> Triangle rasterization for solid triangles of different forms and colors. We could see the triangles suffer from aliasing (jaggies) evident in the zoomed view of the red triangle corner.</figcaption>
        </div>


        <h2 align="center">Task 2: Antialiasing by Supersampling</h2>
        <p>
            Supersampling is equivalent to convolving the image with a 2D box function, resulting in antialiasing. However, we implemented supersampling by rasterizing the image at a higher resolution level based on the sample rate, then the high-res image will be sampled down to the original resolution. 
            We ran into issues with scaling the sample up and down, resulting in our image "jumping" around. Additionally, we spent a lot of time figuring out how to "color" the sample buffer and sample down into the final frame buffer. 
            The resolve_to_framebuffer() method is necessary for transferring the averaged supersamples into the frame buffer. One thing we did not play around or tackle is memomery management since we did not run into any issues during this task, but we ended up come across it in Task 6.  
        </p>

        <div align="center">
            <table style="width=100%">
                <tr>
                    <td>
                        <img src="images/Task2_1sr.png" align="middle" width="400px" />
                        <figcaption align="center"><b>Figure 2.1a:</b> Sample Rate = 1. 'Jaggies' of red triangle corner. </figcaption>
                    </td>
                    <td>
                        <img src="images/Task2_4sr.png" align="middle" width="400px" />
                        <figcaption align="center"><b>Figure 2.1b:</b> Sample Rate = 4. Introducing some supersampling immediately softens the jagged edges. </figcaption>
                    </td>
                </tr>
                <br />
                <tr>
                    <td>
                        <img src="images/Task2_16sr.png" align="middle" width="400px" />
                        <figcaption align="center"><b>Figure 2.1c:</b> Sample Rate = 16. Higher supersampling further reduces aliasing.</figcaption>
                    </td>
                </tr>
            </table>
        </div>


        <h2 align="center">Part 3: Transforms</h2>
        <p>
            Here the Cube Man are stretching himself before a run! To do this I added rotation to all arms and legs pieces and translated them around accordingly.
            
        </p>

        <div align="center">
            <img src="images/Task3_Stretcher.png" align="middle" width="800px" />
            <figcaption align="center"> <b>Figure 3:</b> A basic geometric assembly of Cube Man using translations, rotations, and scalings in homogenous coordinates. 
        </div>
 

        <h2 align="center">Task 4: Barycentric coordinates</h2>
        <p>
            Barycentric coordinates are a system of coordinates that use three reference values and a weighted sum of these values to define a point. Moving along each of the three axes assigns greater weight to a different reference value. The sum of the coordinates must be one, leaving two degrees of freedom. This makes it useful for assigning values to the interior of a triangle in a feature space such as RGB color space or UV texture space, as shown in Figure 4a.</>
        </p>

        <div align="center">
            <table style="width=100%">
                <tr>
                    <td>
                        <img src="images/Barycentric_Triangle.png" align="middle" width="400px" />
                        <figcaption align="center"> <b>Figure 4a:</b> A single triangle colored using barycentric coordinates with the unitary RGB channels (1,0,0), (0,1,0), (0,0,1) located at each of the vertices.  </figcaption>
                    </td>
                    <td>
                        <img src="images/Barycentric_Circle.png" align="middle" width="400px" />
                        <figcaption align="center"><b>Figure 4b:</b> A colorwheel composed of radially fanning acute isosceles triangles. Barycentric coordinates are used to smoothly interpolate the color values. </figcaption>
                    </td>
                </tr>
            </table>


                <div>

                    <h2 align="center">Task 5: "Pixel sampling" for texture mapping</h2>

                    <p align="justify">
                        Texture sampling is similar to pixel sampling in rasterization from Task 1 to 4. However, the challenge in texture mapping is determining which pixel in the texture to sample for a given screenspace position. This is because the screenspace-texturespace relationship can be non-linear, making it unclear which texture value to use. We implemented the mapping from first sampling a pixel in the screen-space. Then we mapped it into the texture space through matrix multiplication. We then pass the mapped texture space into the sampling function to get the texels value back for rasterization.
                        <br />
                        <br />
                        Nearest-neighbor and bilinear sampling are two methods used to address this issue. Nearest-neighbor sampling involves rescaling the UV coordinates and selecting the closest texel, while bilinear sampling, like convoluting with a box filter, involves performing a series of linear interpolations between the four nearest texels. Bilinear sampling produces better results for high-frequency content, such as the latitude and longtitude lines on the map. Magnifying the screen space relative to the texture space results in noticeable differences between the two methods, with nearest-neighbor producing pixelated images and bilinear sampling preserving information about the surroundings.
                        <br />
                        <br />
                        To implement nearest-neighbor pixel sampling for a given UV normalized coordinate, we rescaled the normalized coordinate by the texture map dimensions and identified the closest texel. On the other hand, to implement bilinear sampling we located the four nearest texels in the texture map and performed a series of linear interpolations over 2 axes.
                        <br />
                        <br />
                        <b>Figure 5</b> demonstrates differences between these two pixel sampling methods. The zoomed view of content in the texture mapping illustrate how bilinear sampling surpasses nearest-neighbor. The latitude lines on the map were more consistent in the bilinear sampling images.

                    </p>

                    <div align="center">
                        <table style="width=100%">
                            <tr>
                                <td>
                                    <img src="images/T5_sr1_nearest.png" align="middle" width="400px" />
                                    <figcaption align="center"><b>Figure 5a:<b> Nearest-Neighbor(sample rate = 1).</b></b></figcaption>
                                </td>
                                <td>
                                    <img src="images/T5_sr1_bilinear.png" align="middle" width="400px" />
                                    <figcaption align="center"><b>Figure 5b:<b> Bilinear (sample rate = 1).</b></b></figcaption>
                                </td>
                            </tr>
                            <tr>
                                <td>
                                    <img src="images/T5_sr16_nearest.png" align="middle" width="400px" />
                                    <figcaption align="center"><b>Figure 5c:<b> Nearest-Neighbor (sample rate = 16).</b></b></figcaption>
                                </td>
                                <td>
                                    <img src="images/T5_sr16_bilinear.png" align="middle" width="400px" />
                                    <figcaption align="center"><b>Figure 5b:<b>  Bilinear (sample rate = 16).</b></b></figcaption>
                                </td>
                            </tr>
                        </table>
                    </div>


                    <h2 align="center">Task 6: "Level sampling" with mipmaps for texture mapping</h2>
                    <p align="justify">
                        Level sampling is important in Mipmaps to address issues with minification, where a single pixel on the screen covers several texels in texture space. This presents a challenge for creating coherent visuals.
                        If the texture has high-frequency content in a minified region, moving by a single pixel can result in a texel with unrelated color content. Mipmaps solve this by creating a collection of downsampled textures from which sensible texel values can be passed back to screen space pixels.
                        To determine the appropriate Mipmap level for a given pixel in screen space, we use level sampling. We implemented this by using the columns of the map's Jacobian matrix, which provide an approximate measure of the local pixel footprint in texture space.
                        This information helps us determine which Mipmap level is best suited for coloring a certain part of screenspace based on the degree of minification induced by the map at that local region.
                        <br />
                        <br />
                        In term of performance, pixel sampling is the fastest but produces the poorest antialiasing quality. Level sampling offers better antialiasing quality but requires more memory to store Mipmap levels. The number of samples per pixel provides the best antialiasing quality but requires the most memory and computation time. The optimal technique to use depends on the requirements of the specific application, such as the desired rendering speed, memory usage, and the level of antialiasing quality required.
                        Anectodally, we actually ran into a memory issue with one of the texture images as we ramped up the sampling rate and while keeping lsm at L_NEAREST and psm at P_LINEAR.
                        <b>Figure 6</b> shows that combining nearest-neighbor sampling with level sampling improves render quality through antialiasing.
                    </p>

                    <div align="center">
                        <table style="width=100%">
                            <tr>
                                <td>
                                    <img src="images/Task6_L0_Nearest.png" align="middle" width="400px" />
                                    <figcaption align="center"><b>Figure 6a:<b> LSM = Level 0, PSM = Nearest.</b></b></figcaption>
                                </td>
                                <td>
                                    <img src="images/Task6_L0_Bilinear.png" align="middle" width="400px" />
                                    <figcaption align="center"><b>Figure 6b:<b> LSM = Level 0, PSM = Bilinear.</b></b></figcaption>
                                </td>
                            </tr>
                            <br />
                            <tr>
                                <td>
                                    <img src="images/Task6_Nearest_Nearest.png" align="middle" width="400px" />
                                    <figcaption align="center"><b>Figure 6c:<b> LSM = Nearest, PSM = Nearest.</b></b></figcaption>
                                </td>
                                <td>
                                    <img src="images/Task6_Nearest_Bilinear.png" align="middle" width="400px" />
                                    <figcaption align="center"><b>Figure 6d:<b> LSM = Nearest, PSM = Bilinear.</b></b></figcaption>
                                </td>
                            </tr>
                        </table>
                    </div>

                    <h2 align="center">Part 7: Draw something interesting!</h2>
                    <div align="center">
                        <table style="width=100%">
                        </table>
                    </div>

                </div>

            </table></div>

    </div>

</body>
</html>